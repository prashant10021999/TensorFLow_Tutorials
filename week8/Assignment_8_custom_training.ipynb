{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Assignment 8 - custom_training.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hrXv0rU9sIma"
      },
      "source": [
        "# Custom training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3LXMVuV0VhDr"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NiolgWMPgpwI",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BMiFcDzE7Qu3"
      },
      "source": [
        "## Fit a linear model\n",
        "\n",
        "Use the concepts you have learned so far—`Tensor`, `Variable`, and `GradientTape`—to build and train a simple model.\n",
        "\n",
        "Create a simple linear model, `f(x) = x * x * W2 + x * W1 + b`, which has two variables: `W2` and `W1` (weights) and `b` (bias). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gFzH64Jn9PIm"
      },
      "source": [
        "### Define the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_WRu7Pze7wk8",
        "colab": {}
      },
      "source": [
        "# Initialize the W2, W1 to `2.0`, `5.0`; Bias to `0.0`\n",
        "\"\"\"W2 = 2.0\n",
        "W1 = 5.0\n",
        "b = 0.0 \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18Uf8nzJpbST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(object):\n",
        "    def __init__(self):\n",
        "        self.W2 = tf.Variable(2.0)\n",
        "        self.W1 = tf.Variable(5.0)\n",
        "        self.b = tf.Variable(0.0)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return x * x * self.W2 + x * self.W1 + self.b\n",
        "\n",
        "model = Model()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H11pTAZxSxK",
        "colab_type": "text"
      },
      "source": [
        "### What will be the output of the model before training if we give x = 3.0 as input?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XihlltrBW1tG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"x = 3.0\n",
        "y = x * x * W2 + x * W1 + b\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rc3PNwqXCgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xa6j_yXa-j79"
      },
      "source": [
        "### Define a loss function\n",
        "\n",
        "Use the standard L2 loss:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y0ysUFGY924U",
        "colab": {}
      },
      "source": [
        "# write code here\n",
        "def loss(predict_y, target_y):\n",
        "    return tf.reduce_mean(tf.square(predict_y - target_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qutT_fkl_CBc"
      },
      "source": [
        "### Obtain training data\n",
        "\n",
        "First, synthesize the training data by adding random Gaussian (Normal) noise to the inputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gxPTb-kt_N5m",
        "colab": {}
      },
      "source": [
        "TRUE_W2 = 5.0\n",
        "TRUE_W1 = 3.0\n",
        "TRUE_b = 2.0\n",
        "NUM_EXAMPLES = 1000\n",
        "\n",
        "inputs  = tf.random.normal(shape=[NUM_EXAMPLES])\n",
        "noise   = tf.random.normal(shape=[NUM_EXAMPLES])\n",
        "outputs = inputs * inputs * TRUE_W2 + inputs * TRUE_W1 + TRUE_b + noise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-50nq-wPBsAW"
      },
      "source": [
        "Before training the model, visualize the loss value by plotting the model's predictions in red and the training data in blue:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_eb83LtrB4nt",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(inputs, outputs, c='b')\n",
        "plt.scatter(inputs, model(inputs), c='r')\n",
        "plt.show()\n",
        "\n",
        "print('Current loss: %1.6f' % loss(model(inputs), outputs).numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sSDP-yeq_4jE"
      },
      "source": [
        "### Define a training loop\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MBIACgdnA55X",
        "colab": {}
      },
      "source": [
        "def train(model, inputs, outputs, learning_rate):\n",
        "  # write code here \n",
        "    with tf.GradientTape(persistent=True) as t:\n",
        "        current_loss = loss(model(inputs), outputs)\n",
        "    dw1, dw2, db = t.gradient(current_loss, [model.W1, model.W2, model.b])\n",
        "    model.W1.assign_sub(learning_rate * dw1)\n",
        "    model.W2.assign_sub(learning_rate * dw2)\n",
        "    model.b.assign_sub(learning_rate * db)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XdfkR223D9dW",
        "colab": {}
      },
      "source": [
        "model = Model()\n",
        "\n",
        "# Run for 20 epochs\n",
        "# Use learning rate as 0.1\n",
        "\n",
        "ws1, ws2, bs = [], [], []\n",
        "epochs = range(20)\n",
        "\n",
        "for epoch in epochs:\n",
        "    ws1.append(model.W1.numpy())\n",
        "    ws2.append(model.W2.numpy())\n",
        "    bs.append(model.b.numpy())\n",
        "    current_loss = loss(model(inputs), outputs)\n",
        "\n",
        "    train(model, inputs, outputs, learning_rate=0.1)\n",
        "    print(\"epoch %2d: w1=%1.2f w2=%1.2f b=%1.2f, loss=%2f\" %\n",
        "          (epoch, ws1[-1], ws2[-1], bs[-1], current_loss)\n",
        "         )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTBC_o1QwKfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}